{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15fbc7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              店名                  地址       均消  店評價  \\\n",
      "1                          品馨冰菓室       臺南市中西區中山路128號        無  5.0   \n",
      "2                           落成米糕     臺南市中西區民族路二段241號   均消 $60  4.1   \n",
      "3   NO.8 Specialty Coffee 捌號精品咖啡     臺南市安南區安和路五段173號  均消 $250  4.7   \n",
      "4                          Q皮小龍包       臺南市永康區大灣路440號   均消 $50  4.2   \n",
      "5                    Chun純薏仁。甜點。     臺南市中西區友愛街115巷7號   均消 $90  4.6   \n",
      "6                       YES cafe      臺南市永康區中華二路381號        無  4.5   \n",
      "7                          鳳姐鴨肉飯     臺南市中西區民族路三段190號   均消 $80  4.4   \n",
      "8                          府城騷烤家     臺南市東區臺南市前峰路122號  均消 $400  4.2   \n",
      "9              大河屋 燒肉丼 串燒 台南大潤發店    臺南市北區臨安路二段310號2樓        無  4.7   \n",
      "10                      多多巧思現烤蛋糕      臺南市東區崇善路199之1號   均消 $45  4.2   \n",
      "11                          祝君早安        臺南市東區育樂街109號        無  4.5   \n",
      "12                    U.S. foods  臺南市東區中華東路二段185巷16號   均消 $85  5.0   \n",
      "13                        牛狀元牛肉湯    臺南市麻豆區麻佳路一段87之7號  均消 $200  4.5   \n",
      "14                      新營好吃雞土雞城     臺南市新營區新進路二段332號        無  4.2   \n",
      "15                        邱家小卷米粉       臺南市中西區國華街三段5號   均消 $90  4.4   \n",
      "\n",
      "                               店標籤  \n",
      "1                             [暫無]  \n",
      "2                     [台南小吃, 台南午餐]  \n",
      "3                    [台南早午餐, 台南早餐]  \n",
      "4                     [台南小吃, 台南晚餐]  \n",
      "5     [台南甜點, 台南日本料理, 台南冰品飲料, 台南小吃]  \n",
      "6               [台南蛋糕, 台南早餐, 台南甜點]  \n",
      "7                     [台南小吃, 台南午餐]  \n",
      "8   [台南燒烤, 台南日本料理, 台南精緻高級, 台南約會餐廳]  \n",
      "9             [台南日本料理, 台南晚餐, 台南午餐]  \n",
      "10                    [台南蛋糕, 台南甜點]  \n",
      "11            [台南早午餐, 台南早餐, 台南下午茶]  \n",
      "12            [台南美式料理, 台南早餐, 台南小吃]  \n",
      "13        [台南小吃, 台南宵夜, 台南晚餐, 台南午餐]  \n",
      "14                    [台南晚餐, 台南午餐]  \n",
      "15                    [台南小吃, 台南午餐]  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "\n",
    "page=1\n",
    "list = []\n",
    "for j in range(1,68):\n",
    "    url = 'https://ifoodie.tw/explore/%E5%8F%B0%E5%8D%97%E5%B8%82/list?page={}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    res = requests.get(url.format(page), headers=headers)\n",
    "    html = res.text\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    titlelist = soup.find_all('a', class_=\"jsx-2133253768 click-tracker\")\n",
    "    \n",
    "    for title in titlelist:\n",
    "        urlshop = \"https://ifoodie.tw\" + title.get('href')\n",
    "        reshop = requests.get(urlshop, headers=headers)\n",
    "        htmlshop = reshop.text\n",
    "        shupshop = BeautifulSoup(htmlshop, 'html.parser')\n",
    "\n",
    "        shopname = shupshop.find('a', class_=\"jsx-307016528\")\n",
    "        list.append(shopname.text)\n",
    "        shopinfo = shupshop.find_all('span', class_=\"jsx-1692663080 detail\", limit=2)\n",
    "        # print(titlelist)\n",
    "        list.append(shopinfo[0].text)\n",
    "        try:\n",
    "            if '均消' in shopinfo[1].text:\n",
    "                list.append(shopinfo[1].text)\n",
    "            else:\n",
    "                list.append('無')\n",
    "        except:\n",
    "            list.append('無')\n",
    "        shoprank = shupshop.find('div', class_=\"jsx-1207467136 text\")\n",
    "        list.append(shoprank.text)\n",
    "        shoptag = shupshop.find_all('a', class_=\"jsx-307016528 cat-link\")\n",
    "        tag=[]\n",
    "        for info in shoptag:\n",
    "            tag.append(info.text)\n",
    "        tag.remove('附近')\n",
    "        if len(tag)<1:\n",
    "            tag.append('暫無')\n",
    "        list.append(tag)\n",
    "        # print (\"https://ifoodie.tw\"+title.get('href'))\n",
    "    # print(titleSoupList[0])\n",
    "    # print(list)\n",
    "    page+=1\n",
    "    \n",
    "step = 5\n",
    "slicelist = [list[i:i + step] for i in range(0, len(list), step)]\n",
    "shop_df = pd.DataFrame(slicelist)\n",
    "shop_df.index = shop_df.index + 1  # 自訂索引值\n",
    "shop_df.columns = [\"店名\", \"地址\", \"均消\", \"店評價\",\"店標籤\"]\n",
    "print(shop_df)\n",
    "\n",
    "shop_df.to_excel('shopinfo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df438875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "臺南市中西區中山路128號\n",
      "1\n",
      "['品馨冰菓室', '臺南市中西區中山路128號', '品馨冰菓室', '5.0', ['暫無']]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://ifoodie.tw/restaurant/607412e4baf6d30ba344ac5b-%E5%93%81%E9%A6%A8%E5%86%B0%E8%8F%93%E5%AE%A4'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "res = requests.get(url, headers=headers)\n",
    "html = res.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "list=[]\n",
    "shopname=soup.find('a',class_=\"jsx-307016528\")\n",
    "list.append(shopname.text)\n",
    "shopinfo = soup.find_all('span',class_=\"jsx-1692663080 detail\",limit=2)\n",
    "#print(titlelist)\n",
    "for info in shopinfo:\n",
    "    list.append(info.text)\n",
    "print(shopinfo[0].text)\n",
    "shoprank = soup.find('div',class_=\"jsx-1207467136 text\")\n",
    "list.append(shoprank.text)\n",
    "shoptag = soup.find_all('a', class_=\"jsx-307016528 cat-link\")\n",
    "tag=[]\n",
    "for info in shoptag:\n",
    "    tag.append(info.text)\n",
    "#print(titlelist2.text)\n",
    "tag.remove('附近')\n",
    "if len(tag)<1:\n",
    "    tag.append(\"暫無\")\n",
    "print(len(tag))\n",
    "list.append(tag)\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9d0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "097dab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101936831751294\n"
     ]
    }
   ],
   "source": [
    "import requests,json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://ifoodie.tw/restaurant/6079ce60873d792f8d4d3a8f-%E8%8A%B1%E8%A6%8B%E7%87%92%E8%81%B7%E4%BA%BA%E9%90%B5%E6%9D%BF%E6%96%99%E7%90%86(%E5%8F%B0%E5%8D%97%E5%A4%A7%E5%90%8C%E5%BA%97)'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "res = requests.get(url, headers=headers)\n",
    "html = res.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "loc=str(soup).split('fanPageInfo',1)[1]\n",
    "loc1=loc.split('locationId\":\"',1)[1]\n",
    "loc2=loc1.split('\"',1)[0]\n",
    "#data = json.loads(loc2)\n",
    "#print(soup)\n",
    "print(loc2)\n",
    "#print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "280f98c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'C'], ['D', 'V', 'Y']]\n"
     ]
    }
   ],
   "source": [
    "list=[]\n",
    "list.append(['A','B','C'])\n",
    "list.append(['D','V','Y'])\n",
    "print (list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e9a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd623cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<script type=\"text/javascript\">\n",
      "        (function() {\n",
      "  var docElement = document.documentElement;\n",
      "  var classRE = new RegExp('(^|\\\\s)no-js(\\\\s|$)');\n",
      "  var className = docElement.className;\n",
      "  docElement.className = className.replace(classRE, '$1js$2');\n",
      "})();\n",
      "</script>\n",
      "<script type=\"text/javascript\">\n",
      "(function() {\n",
      "  if ('PerformanceObserver' in window && 'PerformancePaintTiming' in window) {\n",
      "    window.__bufferedPerformance = [];\n",
      "    var ob = new PerformanceObserver(function(e) {\n",
      "      window.__bufferedPerformance.push.apply(window.__bufferedPerformance,e.getEntries());\n",
      "    });\n",
      "    ob.observe({entryTypes:['paint']});\n",
      "  }\n",
      "\n",
      "  window.__bufferedErrors = [];\n",
      "  window.onerror = function(message, url, line, column, error) {\n",
      "    window.__bufferedErrors.push({\n",
      "      message: message,\n",
      "      url: url,\n",
      "      line: line,\n",
      "      column: column,\n",
      "      error: error\n",
      "    });\n",
      "    return false;\n",
      "  };\n",
      "  window.__initialData = {\n",
      "    pending: true,\n",
      "    waiting: []\n",
      "  };\n",
      "  function asyncFetchSharedData(extra) {\n",
      "    var sharedDataReq = new XMLHttpRequest();\n",
      "    sharedDataReq.onreadystatechange = function() {\n",
      "          if (sharedDataReq.readyState === 4) {\n",
      "            if(sharedDataReq.status === 200){\n",
      "              var sharedData = JSON.parse(sharedDataReq.responseText);\n",
      "              window.__initialDataLoaded(sharedData, extra);\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "    sharedDataReq.open('GET', '/data/shared_data/', true);\n",
      "    sharedDataReq.send(null);\n",
      "  }\n",
      "  function notifyLoaded(item, data) {\n",
      "    item.pending = false;\n",
      "    item.data = data;\n",
      "    for (var i = 0;i < item.waiting.length; ++i) {\n",
      "      item.waiting[i].resolve(item.data);\n",
      "    }\n",
      "    item.waiting = [];\n",
      "  }\n",
      "  function notifyError(item, msg) {\n",
      "    item.pending = false;\n",
      "    item.error = new Error(msg);\n",
      "    for (var i = 0;i < item.waiting.length; ++i) {\n",
      "      item.waiting[i].reject(item.error);\n",
      "    }\n",
      "    item.waiting = [];\n",
      "  }\n",
      "  window.__initialDataLoaded = function(initialData, extraData) {\n",
      "    if (extraData) {\n",
      "      for (var key in extraData) {\n",
      "        initialData[key] = extraData[key];\n",
      "      }\n",
      "    }\n",
      "    notifyLoaded(window.__initialData, initialData);\n",
      "  };\n",
      "  window.__initialDataError = function(msg) {\n",
      "    notifyError(window.__initialData, msg);\n",
      "  };\n",
      "  window.__additionalData = {};\n",
      "  window.__pendingAdditionalData = function(paths) {\n",
      "    for (var i = 0;i < paths.length; ++i) {\n",
      "      window.__additionalData[paths[i]] = {\n",
      "        pending: true,\n",
      "        waiting: []\n",
      "      };\n",
      "    }\n",
      "  };\n",
      "  window.__additionalDataLoaded = function(path, data) {\n",
      "    if (path in window.__additionalData) {\n",
      "      notifyLoaded(window.__additionalData[path], data);\n",
      "    } else {\n",
      "      console.error('Unexpected additional data loaded \"' + path + '\"');\n",
      "    }\n",
      "  };\n",
      "  window.__additionalDataError = function(path, msg) {\n",
      "    if (path in window.__additionalData) {\n",
      "      notifyError(window.__additionalData[path], msg);\n",
      "    } else {\n",
      "      console.error('Unexpected additional data encountered an error \"' + path + '\": ' + msg);\n",
      "    }\n",
      "  };\n",
      "  \n",
      "})();\n",
      "</script>\n",
      "<script type=\"text/javascript\">\n",
      "\n",
      "/*\n",
      " Copyright 2018 Google Inc. All Rights Reserved.\n",
      " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      " you may not use this file except in compliance with the License.\n",
      " You may obtain a copy of the License at\n",
      "\n",
      "     http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      " Unless required by applicable law or agreed to in writing, software\n",
      " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      " See the License for the specific language governing permissions and\n",
      " limitations under the License.\n",
      "*/\n",
      "\n",
      "(function(){function g(a,c){b||(b=a,f=c,h.forEach(function(a){removeEventListener(a,l,e)}),m())}function m(){b&&f&&0<d.length&&(d.forEach(function(a){a(b,f)}),d=[])}function n(a,c){function k(){g(a,c);d()}function b(){d()}function d(){removeEventListener(\"pointerup\",k,e);removeEventListener(\"pointercancel\",b,e)}addEventListener(\"pointerup\",k,e);addEventListener(\"pointercancel\",b,e)}function l(a){if(a.cancelable){var c=performance.now(),b=a.timeStamp;b>c&&(c=+new Date);c-=b;\"pointerdown\"==a.type?n(c,\n",
      "a):g(c,a)}}var e={passive:!0,capture:!0},h=[\"click\",\"mousedown\",\"keydown\",\"touchstart\",\"pointerdown\"],b,f,d=[];h.forEach(function(a){addEventListener(a,l,e)});window.perfMetrics=window.perfMetrics||{};window.perfMetrics.onFirstInputDelay=function(a){d.push(a);m()}})();\n",
      "</script>\n",
      "<script crossorigin=\"anonymous\" src=\"/static/scripts/jquery.js/a4e77326039e.js\" type=\"text/javascript\"></script>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c0d21cafde34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'window'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'= {'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mjs_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "import requests,json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib import parse\n",
    "import time\n",
    "\n",
    "url = 'https://www.instagram.com/explore/locations/223774491017756/'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'\n",
    "    \n",
    "    }\n",
    "\n",
    "res = requests.get(url, headers=headers)\n",
    "html = res.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "scr=soup.find_all('script',type=\"text/javascript\")\n",
    "NEXT_URL = 'https://www.instagram.com/graphql/query/?query_hash=36bd0f2bf5911908de389b8ceaa3be6d&variables='\n",
    "queryhash='36bd0f2bf5911908de389b8ceaa3be6d'\n",
    "jso = {\"id\": \"\", \"first\": 12, \"after\": \"\"}\n",
    "all_imgs_url = []\n",
    "for tag in scr:\n",
    "    print(tag)\n",
    "    if (tag.string).strip().startswith('window'):\n",
    "        data = (tag.string).split('= {')[1][:-1]  \n",
    "        js_data = json.loads('{' + data)\n",
    "        id = js_data[\"entry_data\"][\"LocationsPage\"][0][\"graphql\"][\"location\"][\"id\"]\n",
    "        edges = js_data[\"entry_data\"][\"LocationsPage\"][0][\"graphql\"][\"location\"][\"edge_location_to_media\"][\"edges\"]\n",
    "        end_cursor = js_data[\"entry_data\"][\"LocationsPage\"][0][\"graphql\"][\"location\"][\"edge_location_to_media\"][\"page_info\"][\"end_cursor\"]\n",
    "        has_next = js_data[\"entry_data\"][\"LocationsPage\"][0][\"graphql\"][\"location\"][\"edge_location_to_media\"][\"page_info\"][\"has_next_page\"]\n",
    "        for edge in edges:\n",
    "            all_imgs_url.append(edge[\"node\"][\"display_url\"])\n",
    "            #print(edge[\"node\"][\"display_url\"])\n",
    "            \n",
    "        while has_next :\n",
    "            jso[\"id\"] = id\n",
    "            jso[\"first\"] = 12\n",
    "            jso[\"after\"] = end_cursor\n",
    "            text = json.dumps(jso)\n",
    "            url = NEXT_URL+text.replace(\" \",\"\")\n",
    "            res = requests.get(url,headers=headers,timeout=10)\n",
    "            html = json.loads(res.content.decode(encoding='utf-8'))\n",
    "            \n",
    "            \n",
    "            print(html)\n",
    "#            html = json.loads(res.content.decode(encoding='utf-8'))\n",
    "#            has_next = html[\"data\"][\"user\"][\"edge_owner_to_timeline_media\"][\"page_info\"][\"has_next_page\"]\n",
    "#            end_cursor = html[\"data\"][\"user\"][\"edge_owner_to_timeline_media\"][\"page_info\"][\"end_cursor\"]\n",
    "#            edges = html[\"data\"][\"user\"][\"edge_owner_to_timeline_media\"][\"edges\"]\n",
    "#            for edge in edges:\n",
    "#                all_imgs_url.append(edge[\"node\"][\"display_url\"])\n",
    "#                print(edge[\"node\"][\"display_url\"])\n",
    "                    \n",
    "                \n",
    "                \n",
    "     \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c37dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"555588884444\", \"first\": 12, \"after\": \"rigjre8njhet890rhj0we890ujergioj\"}\n",
      "https://www.instagram.com/graphql/query/?query_hash=36bd0f2bf5911908de389b8ceaa3be6d&variables={\"id\":\"555588884444\",\"first\":12,\"after\":\"rigjre8njhet890rhj0we890ujergioj\"}\n"
     ]
    }
   ],
   "source": [
    "jso = {\"id\": \"555588884444\", \"first\": 12, \"after\": \"rigjre8njhet890rhj0we890ujergioj\"}\n",
    "text = json.dumps(jso)\n",
    "print(text)\n",
    "url = NEXT_URL+text.replace(\" \",\"\")\n",
    "print(url)\n",
    "html = json.loads(res.content.decode(encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36096b1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-79ef9ed965af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m199\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m199\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m199\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.float32,shape=[1])\n",
    "b = tf.placeholder(tf.float32,shape=[199,99])\n",
    "c  = tf.placeholder(tf.float32,shape=[199,199,99])\n",
    "d = tf.get_variable(shape=[1], name='b', dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    var_list = tf.trainable_variables()\n",
    "    saver = tf.train.Saver(var_list=var_list)\n",
    "    saver.save(sess,'./test')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver = tf.train.import_meta_graph('./test.meta')\n",
    "    graph = tf.get_default_graph()\n",
    "    graph_op = graph.get_operations()\n",
    "    for i in graph_op:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69e6780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435258e-9b7c-4abe-8ce7-f8cf493e931a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
